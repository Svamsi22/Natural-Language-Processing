{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a8492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sikha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be96804f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿\n",
      "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your text file\n",
    "file_path = r\"C:\\Users\\sikha\\OneDrive\\Desktop\\1661-0.txt\"# we can insert any path where the text is saved\n",
    "\n",
    "# Read the content of the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    book_text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c19bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Text Data\n",
    "# Assume 'text_data' is your text data in string format\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([book_text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3cb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences and labels\n",
    "input_sequences = tokenizer.texts_to_sequences([book_text])[0]\n",
    "\n",
    "sequences = []\n",
    "for i in range(1, len(input_sequences)):\n",
    "    if i >= max_sequence_length:\n",
    "        n_gram_sequence = input_sequences[i - max_sequence_length : i + 1]\n",
    "        sequences.append(n_gram_sequence)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "\n",
    "# Ensure that X has the correct shape\n",
    "X = pad_sequences(X, maxlen=input_sequence_length, padding='pre')\n",
    "\n",
    "# Correct the value for num_classes to be the vocabulary size\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)  # Use total_words instead of total_words * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16559240",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\sikha\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sikha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3477/3477 [==============================] - 103s 28ms/step - loss: 6.4162 - accuracy: 0.0715\n",
      "Epoch 2/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 5.6116 - accuracy: 0.1232\n",
      "Epoch 3/50\n",
      "3477/3477 [==============================] - 96s 28ms/step - loss: 5.1900 - accuracy: 0.1487\n",
      "Epoch 4/50\n",
      "3477/3477 [==============================] - 102s 29ms/step - loss: 4.8660 - accuracy: 0.1676\n",
      "Epoch 5/50\n",
      "3477/3477 [==============================] - 99s 29ms/step - loss: 4.5841 - accuracy: 0.1834\n",
      "Epoch 6/50\n",
      "3477/3477 [==============================] - 99s 28ms/step - loss: 4.3269 - accuracy: 0.2021\n",
      "Epoch 7/50\n",
      "3477/3477 [==============================] - 97s 28ms/step - loss: 4.0878 - accuracy: 0.2212\n",
      "Epoch 8/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 3.8653 - accuracy: 0.2443\n",
      "Epoch 9/50\n",
      "3477/3477 [==============================] - 101s 29ms/step - loss: 3.6530 - accuracy: 0.2705\n",
      "Epoch 10/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 3.4530 - accuracy: 0.2970\n",
      "Epoch 11/50\n",
      "3477/3477 [==============================] - 99s 28ms/step - loss: 3.2663 - accuracy: 0.3244\n",
      "Epoch 12/50\n",
      "3477/3477 [==============================] - 99s 28ms/step - loss: 3.0911 - accuracy: 0.3524\n",
      "Epoch 13/50\n",
      "3477/3477 [==============================] - 97s 28ms/step - loss: 2.9284 - accuracy: 0.3791\n",
      "Epoch 14/50\n",
      "3477/3477 [==============================] - 104s 30ms/step - loss: 2.7785 - accuracy: 0.4061\n",
      "Epoch 15/50\n",
      "3477/3477 [==============================] - 101s 29ms/step - loss: 2.6366 - accuracy: 0.4327\n",
      "Epoch 16/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 2.5065 - accuracy: 0.4575\n",
      "Epoch 17/50\n",
      "3477/3477 [==============================] - 99s 29ms/step - loss: 2.3866 - accuracy: 0.4800\n",
      "Epoch 18/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 2.2731 - accuracy: 0.5028\n",
      "Epoch 19/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 2.1688 - accuracy: 0.5232\n",
      "Epoch 20/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 2.0710 - accuracy: 0.5431\n",
      "Epoch 21/50\n",
      "3477/3477 [==============================] - 99s 28ms/step - loss: 1.9779 - accuracy: 0.5613\n",
      "Epoch 22/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 1.8950 - accuracy: 0.5782\n",
      "Epoch 23/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 1.8163 - accuracy: 0.5943\n",
      "Epoch 24/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 1.7419 - accuracy: 0.6102\n",
      "Epoch 25/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 1.6736 - accuracy: 0.6249\n",
      "Epoch 26/50\n",
      "3477/3477 [==============================] - 103s 30ms/step - loss: 1.6110 - accuracy: 0.6368\n",
      "Epoch 27/50\n",
      "3477/3477 [==============================] - 103s 29ms/step - loss: 1.5510 - accuracy: 0.6491\n",
      "Epoch 28/50\n",
      "3477/3477 [==============================] - 106s 31ms/step - loss: 1.4971 - accuracy: 0.6614\n",
      "Epoch 29/50\n",
      "3477/3477 [==============================] - 102s 29ms/step - loss: 1.4456 - accuracy: 0.6708\n",
      "Epoch 30/50\n",
      "3477/3477 [==============================] - 103s 30ms/step - loss: 1.3990 - accuracy: 0.6796\n",
      "Epoch 31/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 1.3551 - accuracy: 0.6907\n",
      "Epoch 32/50\n",
      "3477/3477 [==============================] - 99s 28ms/step - loss: 1.3127 - accuracy: 0.7002\n",
      "Epoch 33/50\n",
      "3477/3477 [==============================] - 96s 28ms/step - loss: 1.2758 - accuracy: 0.7068\n",
      "Epoch 34/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 1.2388 - accuracy: 0.7147\n",
      "Epoch 35/50\n",
      "3477/3477 [==============================] - 102s 29ms/step - loss: 1.2039 - accuracy: 0.7237\n",
      "Epoch 36/50\n",
      "3477/3477 [==============================] - 99s 28ms/step - loss: 1.1746 - accuracy: 0.7284\n",
      "Epoch 37/50\n",
      "3477/3477 [==============================] - 105s 30ms/step - loss: 1.1444 - accuracy: 0.7350\n",
      "Epoch 38/50\n",
      "3477/3477 [==============================] - 98s 28ms/step - loss: 1.1181 - accuracy: 0.7393\n",
      "Epoch 39/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 1.0918 - accuracy: 0.7460\n",
      "Epoch 40/50\n",
      "3477/3477 [==============================] - 99s 29ms/step - loss: 1.0687 - accuracy: 0.7510\n",
      "Epoch 41/50\n",
      "3477/3477 [==============================] - 100s 29ms/step - loss: 1.0481 - accuracy: 0.7535\n",
      "Epoch 42/50\n",
      "3477/3477 [==============================] - 101s 29ms/step - loss: 1.0220 - accuracy: 0.7601\n",
      "Epoch 43/50\n",
      "3477/3477 [==============================] - 110s 32ms/step - loss: 1.0068 - accuracy: 0.7627\n",
      "Epoch 44/50\n",
      "3477/3477 [==============================] - 114s 33ms/step - loss: 0.9879 - accuracy: 0.7664\n",
      "Epoch 45/50\n",
      "3477/3477 [==============================] - 115s 33ms/step - loss: 0.9671 - accuracy: 0.7717\n",
      "Epoch 46/50\n",
      "3477/3477 [==============================] - 115s 33ms/step - loss: 0.9506 - accuracy: 0.7745\n",
      "Epoch 47/50\n",
      "3477/3477 [==============================] - 110s 32ms/step - loss: 0.9377 - accuracy: 0.7766\n",
      "Epoch 48/50\n",
      "3477/3477 [==============================] - 113s 33ms/step - loss: 0.9279 - accuracy: 0.7791\n",
      "Epoch 49/50\n",
      "3477/3477 [==============================] - 102s 29ms/step - loss: 0.9050 - accuracy: 0.7842\n",
      "Epoch 50/50\n",
      "3477/3477 [==============================] - 104s 30ms/step - loss: 0.8925 - accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=50, verbose=1)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('word_generate_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c2835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer Weights: [array([[ 3.13203372e-02, -4.02163267e-02,  1.11728907e-03, ...,\n",
      "        -4.05531526e-02,  3.68467309e-02,  7.76745006e-03],\n",
      "       [ 4.39106345e-01, -2.45231897e-01,  3.71920764e-01, ...,\n",
      "         6.60158575e-01, -7.48053968e-01, -1.34231460e+00],\n",
      "       [ 4.12231982e-01,  5.05305052e-01,  2.97618657e-01, ...,\n",
      "         1.28584325e-01, -3.14437924e-03, -4.21364278e-01],\n",
      "       ...,\n",
      "       [ 9.62836319e-04, -2.45681286e-01, -2.48475760e-01, ...,\n",
      "        -1.54530257e-01,  1.00785755e-01,  7.81760588e-02],\n",
      "       [-7.50583112e-01,  1.27602175e-01,  3.03465903e-01, ...,\n",
      "        -9.91650969e-02,  2.04800159e-01,  3.13944846e-01],\n",
      "       [-5.30315470e-03,  2.27215007e-01,  2.43006814e-02, ...,\n",
      "         1.45271897e-01,  9.71059874e-02, -3.27641815e-02]], dtype=float32)]\n",
      "LSTM Layer Weights: [array([[-0.37841117,  0.03630177,  1.3436892 , ...,  1.9185373 ,\n",
      "        -0.36676666, -0.03729386],\n",
      "       [-0.5437339 ,  0.07017142,  0.30201882, ..., -0.74621403,\n",
      "         1.2948785 ,  1.0318844 ],\n",
      "       [-0.23342766, -0.51416886,  0.7946014 , ...,  0.57888925,\n",
      "         0.4300552 ,  0.09094264],\n",
      "       ...,\n",
      "       [-0.12366807, -0.2593302 , -0.5340207 , ..., -0.33686313,\n",
      "        -0.04735338, -0.5086036 ],\n",
      "       [ 0.72917557,  0.27767393,  0.4365117 , ...,  0.00515027,\n",
      "        -1.197252  ,  0.22198541],\n",
      "       [ 0.57321554,  1.1453279 ,  0.45137948, ..., -1.0695598 ,\n",
      "        -1.1318717 , -0.00804392]], dtype=float32), array([[-1.9214786 , -0.98340714, -0.6897885 , ...,  0.60730827,\n",
      "         1.1017389 , -0.25966498],\n",
      "       [-0.07431534,  1.5517843 , -0.5499206 , ...,  0.57787746,\n",
      "        -0.7675075 , -0.511912  ],\n",
      "       [-0.39464453,  0.6913953 ,  0.6560902 , ...,  1.0404501 ,\n",
      "        -0.4548717 ,  1.2809694 ],\n",
      "       ...,\n",
      "       [-0.18553257,  0.37070492,  0.9610842 , ..., -0.70528173,\n",
      "         0.6790923 ,  0.36154598],\n",
      "       [-0.9881435 , -0.73076284, -0.6159288 , ...,  0.2365918 ,\n",
      "         0.4680646 , -0.7997091 ],\n",
      "       [ 0.42581743,  0.61321574, -0.06463888, ...,  1.1089228 ,\n",
      "         0.30900103, -1.5800568 ]], dtype=float32), array([ 2.118051  ,  1.541103  ,  1.3956676 ,  0.8880491 ,  1.0621564 ,\n",
      "        1.5622574 ,  0.35964093,  2.2810764 ,  1.7059875 ,  0.9966815 ,\n",
      "        1.4171888 ,  1.5211977 ,  1.5249863 ,  0.3769222 ,  0.6726398 ,\n",
      "        0.8204943 ,  1.2739094 ,  1.280328  ,  0.19430782,  1.8043798 ,\n",
      "        0.33562684,  0.79448307,  1.5265689 ,  0.48783764,  2.0675347 ,\n",
      "        1.7374743 ,  0.23800887,  1.314755  ,  1.5156509 ,  1.9428742 ,\n",
      "       -0.02685285,  0.35832244,  1.3908235 ,  1.9729886 ,  1.3241841 ,\n",
      "        1.696136  ,  1.7134979 ,  1.0482523 ,  1.0086746 ,  1.441195  ,\n",
      "        0.7872423 ,  1.2534918 ,  1.5039506 ,  1.1024045 ,  0.38988438,\n",
      "        1.5469173 ,  1.1794217 ,  0.6077566 ,  0.46407047,  1.0791609 ,\n",
      "        1.8063263 ,  1.4022095 ,  0.750363  ,  1.2891208 ,  1.1443264 ,\n",
      "        0.9525685 ,  0.5017935 ,  1.4628035 ,  0.944864  ,  2.2038534 ,\n",
      "        1.6123713 ,  1.95854   ,  0.20804146,  1.3751016 ,  0.94049954,\n",
      "        0.78528774,  0.99802524,  1.5314491 ,  0.6945642 ,  1.6492718 ,\n",
      "        0.23643635,  1.281504  ,  1.4859267 ,  1.625711  ,  1.3245624 ,\n",
      "        2.113082  ,  0.78941137,  1.2593677 ,  1.1472495 , -0.12253566,\n",
      "        1.9695733 ,  1.196022  ,  2.055598  ,  1.1772434 ,  0.53762144,\n",
      "        2.2207508 ,  0.6664699 ,  1.4308267 ,  1.7021774 ,  1.3324724 ,\n",
      "        1.7102181 ,  1.2619864 ,  1.0799401 ,  1.105439  ,  1.1018428 ,\n",
      "        2.0925016 ,  0.6825422 ,  1.1112795 ,  0.51423395,  1.3768121 ,\n",
      "        0.06893362,  1.5549741 ,  1.2026314 ,  1.8112673 ,  0.3571917 ,\n",
      "        1.9777435 ,  1.6095589 ,  1.5362186 ,  1.3500795 ,  1.7712709 ,\n",
      "        1.196384  ,  0.8838091 ,  1.9412829 ,  1.8189867 ,  1.4227427 ,\n",
      "        1.5895951 ,  0.45492336,  1.1548367 ,  2.311142  ,  1.2826062 ,\n",
      "        1.7730315 ,  1.2713497 ,  0.6301023 ,  1.3261826 ,  1.1680721 ,\n",
      "        1.4226956 ,  1.7661798 ,  1.7920368 ,  1.3533016 ,  0.7925185 ,\n",
      "        1.6951199 ,  2.0988858 ,  1.1686593 ,  1.3420488 ,  1.1460633 ,\n",
      "        0.88278246,  1.2799835 ,  1.4875554 ,  0.70693296,  1.2912065 ,\n",
      "        1.368962  ,  2.1026058 ,  0.90261394,  1.1766472 ,  2.1718936 ,\n",
      "        0.7103343 ,  1.1621625 ,  1.7658308 ,  1.6619451 ,  1.1968307 ,\n",
      "        1.5780461 ,  1.1761838 ,  1.8158323 ,  0.6815881 ,  0.60261166,\n",
      "        1.4410299 ,  2.1993625 ,  1.282351  ,  1.7086449 ,  0.61874485,\n",
      "        1.7992035 ,  0.85151607,  2.1637752 ,  1.6959485 ,  1.2032306 ,\n",
      "        1.3884759 ,  0.6129465 ,  0.5908048 ,  1.3809793 ,  0.8243331 ,\n",
      "        2.0952308 ,  0.73861605,  1.5000713 ,  1.0945369 ,  1.0704567 ,\n",
      "        1.1423339 ,  1.2392472 ,  1.2999058 ,  1.4643512 ,  1.7249037 ,\n",
      "        1.0080942 ,  0.6669037 ,  0.8766004 ,  2.0144596 ,  1.8823055 ,\n",
      "        0.53378   ,  2.2050412 ,  0.10365342,  0.6840345 ,  1.45029   ,\n",
      "        0.86123985,  0.8303665 ,  1.6025505 ,  1.166363  ,  1.3788837 ,\n",
      "        0.62015367,  1.0670105 ,  0.57862514,  1.7956021 ,  1.2021636 ,\n",
      "        0.61666465, -0.03102759,  0.19535409,  0.12901667, -0.28579617,\n",
      "       -0.23903392,  0.09706803,  0.11065814,  0.676437  ,  0.05731659,\n",
      "        0.17663345, -0.03408822,  0.17845252,  0.44657552, -0.18870112,\n",
      "       -0.2264032 ,  0.03000624,  0.27312925, -0.15674122,  0.5192392 ,\n",
      "        0.21346076,  0.1635546 , -0.20775959, -0.15558712,  0.44996655,\n",
      "       -0.1581989 , -0.22364025, -0.1623995 , -0.21256009,  0.13665845,\n",
      "       -0.36704493,  0.23745452,  0.15778601, -0.23305668,  0.5351741 ,\n",
      "        0.30336308, -0.17808838, -0.07362719,  0.4497844 , -0.11140079,\n",
      "        0.06172836, -0.01795407, -0.02396159, -0.20410095, -0.13106379,\n",
      "        0.61867374,  0.5104404 , -0.46816808,  0.2883867 ,  0.17448024,\n",
      "        0.14825723,  0.30993688,  0.27382985,  0.22842646, -0.15023683,\n",
      "       -0.14802216, -0.46752995, -0.01479325,  0.39441574,  0.3782501 ,\n",
      "       -0.01802688, -0.24985282, -0.15638827,  0.05891405, -0.50437415,\n",
      "        0.28110778,  0.36391288,  0.11096479, -0.3512028 ,  0.04210173,\n",
      "        0.28542188,  0.39824522, -0.55192494, -0.10843869, -0.04797189,\n",
      "       -0.30634412,  0.1444212 , -0.00645515, -0.11983401,  0.32353786,\n",
      "        0.20058501,  0.17485969, -0.30288643,  0.01606993, -0.02864202,\n",
      "        0.280553  , -0.26814216,  0.2809824 , -0.41083923, -0.02100616,\n",
      "       -0.24877602,  0.14957295, -0.17085658, -0.092005  , -0.67441267,\n",
      "       -0.08357071,  0.31222847,  0.15893194, -0.4886336 ,  0.17808679,\n",
      "        1.8436353 ,  1.6513953 ,  0.7682043 , -0.31093836,  1.1258396 ,\n",
      "        1.635432  ,  0.16637585,  1.8814884 ,  0.654279  ,  0.33830228,\n",
      "        1.7158155 ,  0.5200779 ,  1.1925251 , -0.91407937, -1.0145886 ,\n",
      "       -0.42683706,  1.9356776 ,  1.7585    , -1.4217883 ,  2.2566593 ,\n",
      "       -0.04150003, -0.26139817,  1.6369132 ,  0.7849618 ,  1.1708021 ,\n",
      "        1.0255617 , -0.46039823,  0.9926404 ,  1.0829396 ,  1.7514362 ,\n",
      "       -1.2988818 , -0.589593  ,  1.785149  ,  1.908192  ,  2.4242325 ,\n",
      "        1.8979036 ,  0.62789285,  0.13252264,  1.4212198 ,  1.3782333 ,\n",
      "        0.03778625,  0.9850464 ,  1.9406322 ,  1.76071   , -0.84405804,\n",
      "        0.7922926 ,  0.54518443, -1.8469408 , -0.00927272,  1.2955351 ,\n",
      "        1.5524619 ,  2.3043635 , -0.44726416,  1.4829221 ,  1.2876985 ,\n",
      "        1.8053064 , -1.310059  ,  0.97083235, -0.46622837,  1.0562484 ,\n",
      "        1.683322  ,  1.8743252 , -0.9045164 ,  1.5294724 ,  0.96699566,\n",
      "       -0.3549935 ,  1.5021151 ,  1.7774967 ,  1.1016593 ,  1.7121801 ,\n",
      "       -0.20724468,  1.3566355 , -0.23026057,  1.7369686 ,  1.6825018 ,\n",
      "        1.1959267 ,  1.2850627 ,  0.28713772,  1.3646195 ,  0.23322582,\n",
      "        1.6075864 ,  1.4376229 ,  1.4638628 ,  1.8012666 ,  0.8542453 ,\n",
      "        0.9711196 ,  1.6463065 ,  1.9822178 ,  0.7822003 ,  1.271767  ,\n",
      "        1.9745572 ,  1.200648  ,  1.0197984 ,  1.4651183 ,  1.7200491 ,\n",
      "        1.9041418 ,  0.6736961 ,  1.2157395 , -1.2522254 ,  0.71597373],\n",
      "      dtype=float32)]\n",
      "Dense Layer Weights: [array([[ 0.8593058 , -1.0211655 , -0.44473842, ..., -0.00770342,\n",
      "         0.24882366,  0.7400188 ],\n",
      "       [-0.18096027,  1.0737717 ,  0.64883816, ..., -0.45514265,\n",
      "        -0.02989197, -0.4622576 ],\n",
      "       [-0.68856895, -0.73259   ,  1.2042319 , ..., -1.1926135 ,\n",
      "         1.2054994 , -1.0516362 ],\n",
      "       ...,\n",
      "       [-0.53103495, -0.69351596, -1.5950555 , ...,  0.03430691,\n",
      "         0.03459927, -0.2007215 ],\n",
      "       [ 1.929351  ,  0.03493325, -0.2582558 , ...,  0.76833045,\n",
      "         5.547125  ,  3.3007455 ],\n",
      "       [-0.5239663 ,  1.3080983 ,  0.9500259 , ...,  0.01841542,\n",
      "        -0.4912194 , -0.24041706]], dtype=float32), array([-6.409684 , -1.9399229, -2.1019378, ..., -1.9930134, -1.4313502,\n",
      "       -3.5575085], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Get the weights of each layer\n",
    "embedding_layer_weights = model.layers[0].get_weights()\n",
    "lstm_layer_weights = model.layers[1].get_weights()\n",
    "dense_layer_weights = model.layers[2].get_weights()\n",
    "\n",
    "# You can print or use these weights as needed\n",
    "print(\"Embedding Layer Weights:\", embedding_layer_weights)\n",
    "print(\"LSTM Layer Weights:\", lstm_layer_weights)\n",
    "print(\"Dense Layer Weights:\", dense_layer_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ad80ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an excellent offers in this mccarthy your husband is a\n"
     ]
    }
   ],
   "source": [
    "def word_generate(seed_text, next_words, model, max_sequence_length):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "        predicted_probabilities = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probabilities)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "# Step 4: Generate Text Using the Trained Model\n",
    "generated_text = word_generate(\"This is\", 10, model, max_sequence_length)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f5987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
